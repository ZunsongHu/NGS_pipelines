#obj_out=list(SE=SummarizedExperiment(assays=list(vst=df_vst,counts=df_counts), colData = diag))
#assays(obj_in$SE)$counts=count_2042
#assays(obj_in$SE)[['counts']]=count_2042
#obj_in1$SE=obj_in1$SE[,row.names(df_colData)] subset samples
#print(paste0("Input N(samples),N(features): ",paste0(dim(matrix_),collapse = ",")))
#obj_in$SE[["cluster_Phenograph"]]=df_cluster$cluster_Phenograph add new variable

## Import required libraries
options(warn=-1)
suppressPackageStartupMessages({
  library(Rtsne)
  # library(caret)
  library(tidyr)
  library(dplyr)
  library(ggplot2)
  library(ggrepel)
  # library(ggpubr)
  # library(DESeq2)
  library(stringr)
  library(SummarizedExperiment)
  library(edgeR)
  
})
options(warn=0)

# install.packages("umap")
# BiocManager::install("SummarizedExperiment")

#args <- commandArgs(trailingOnly = TRUE)
#print(args)

#file_tsv=args[1]

quitely_load_library=function(name){
  suppressMessages(suppressWarnings(library(name,quietly = T,verbose=F,character.only = T)))
}



# Read files ------------------------

read_blast=function(file_blast){
  id=word(basename(file_blast),1,sep="[.]")
  cat(paste0(id,"\n"))
  df_blast=vroom::vroom(file_blast,progress = FALSE,col_names = F,show_col_types =F)
  names(df_blast)=c('qseqid','qlen','evalue','bitscore','score','pident','nident','sseqid','slen','qstart','qend','sstart','send','length')
  df_blast$id=id
  df_blast
}

# expression matrix --------------------
get_count_matrix=function(files,header="yes",sep="\t",count_field_num=2){
  for(file in files){
    print(match(file,files))
    id=word(basename(file),1,sep="[.]")
    
    if(tolower(header)=="yes"){
      count_one=read.table(file,header = T,stringsAsFactors = F,sep=sep) 
    }
    
    if(!tolower(header)=="yes"){
      count_one=read.table(file,header = T,stringsAsFactors = F,sep=sep) 
    }
    count_one=count_one[c(1,count_field_num)]
    
    names(count_one)[c(1,2)]=c("feature",id)
    if(match(file,files)==1){count_all=count_one}
    if(match(file,files)>1){count_all=count_all %>% left_join(count_one)}
  }
  count_all
}




get_htseq_matrix=function(files_htseq){
  for (file_htseq in files_htseq){
    id=word(basename(file_htseq),1,sep="[.]")
    df=read.table(file_htseq,header = F,sep = "\t") %>%
      filter(grepl("ENSG",V1))
    names(df)=c("feature",id)
    print(match(file_htseq,files_htseq))
    if (match(file_htseq,files_htseq)==1){count_all=df}
    if (match(file_htseq,files_htseq)>1){count_all=count_all %>% left_join(df)}
  }
  count_all=count_all %>% arrange(feature)
  count_all
}


get_Featurecounts_matrix=function(files_featurecounts){
  for (file_featurecounts in files_featurecounts){
    df=read.table(file_featurecounts,header = T,sep = "\t")
    df=df[c(1,ncol(df))]
    
    names(df)=c("feature",word(basename(file_featurecounts),1,sep="[.]"))
    print(match(file_featurecounts,files_featurecounts))
    if (match(file_featurecounts,files_featurecounts)==1){count_all_featurecounts=df}
    if (match(file_featurecounts,files_featurecounts)>1){count_all_featurecounts=count_all_featurecounts %>% left_join(df)}
  }
  count_all_featurecounts=count_all_featurecounts %>% arrange(feature)
  count_all_featurecounts
}




get_vst_matrix=function(files){
  for(file in files){
    print(match(file,files))
    id=word(basename(file),1,sep="[.]")
    count_one=read.table(file,header = T,stringsAsFactors = F) 
    count_one[,2]=round(unlist(count_one[2]),2)
    if(match(file,files)==1){vst_all=count_one}
    if(match(file,files)>1){vst_all=vst_all %>% left_join(count_one)}
  }
  vst_all
}

get_junction_matrix=function(files){
  for(file in files){
    print(match(file,files))
    id=word(basename(file),1,sep="[.]")
    count_one=read_tsv(file)
    names(count_one)=c("feature",id)
    if(match(file,files)==1){out_all=count_one}
    if(match(file,files)>1){out_all=out_all %>% left_join(count_one)}
  }
  out_all
}



#Create RNA object ---------------------
createObj_from_Counts=function(counts,colData){
  if(!all(colnames(counts)==row.names(colData))){stop("Colnames of counts not equal to row names of ColData")}
  obj_=list()
  obj_[["SE"]]=SummarizedExperiment(assays=list(counts=counts), colData = colData)
  obj_
}

#General usage ----

get_dfId=function(inObj){

  df_id=data.frame(id=colnames(assays(inObj$SE)$vst),stringsAsFactors = F)
  df_id

}

get_diag_mask=function(x){
  ifelse(x %in% c("Near haploid","Low hyperdiploid"),"Hyperdiploid",
         ifelse(x =="KMT2A-like","KMT2A",
                ifelse(x=="ZNF384-like","ZNF384",
                       ifelse(x=="ETV6::RUNX1-like","ETV6::RUNX1",
                              ifelse(x=="CRLF2(non-Ph-like)","Ph",
                                     ifelse(x=="Ph-like","Ph",x))))))
}

get_pred_category=function(x){
  df_=data.frame(x=word(x,1,sep="[|]"),stringsAsFactors = F) %>%
    dplyr::mutate(label=word(x,1,sep="[(]"),
           score=as.numeric(gsub("[)]","",word(x,2,sep="[()]"))),
           score_equal1=ifelse(score==1,"Yes",NA),
           score_more0.8=ifelse(score>=0.8,"Yes",NA)
    ) %>%
    group_by(label) %>% dplyr::mutate(n_label=n()) %>%
    group_by(label,score_equal1) %>% dplyr::mutate(n_label_equal1=n(),n_label_equal1=ifelse(is.na(score_equal1),0,n_label_equal1)) %>%
    group_by(label,score_more0.8) %>% dplyr::mutate(n_label_more0.8=n(),n_label_more0.8=ifelse(is.na(score_more0.8),0,n_label_more0.8)) %>%
    arrange(desc(n_label),desc(score)) %>% ungroup

  df_1=df_ %>% slice_head(n=1) %>%
    dplyr::mutate(
      pred_category=ifelse(n_label==n_method & n_label_equal1>=1,"Definitive1",
                           ifelse(n_label>=(n_method-1) & n_label_equal1>=2,"Definitive2",
                                  ifelse(n_label==n_method & n_label_more0.8>=1,"High1",
                                         ifelse(n_label_equal1>=1,"High2",
                                                ifelse(n_label==n_method,"Medium",
                                                       ifelse(n_label==(n_method-1),"Low",
                                                              ifelse(n_label==1,"Ambiguous",NA)))))))
    )

  paste0(df_1$label,"@",df_1$pred_category)

}

cal_sensitivity_specificity=function(indata,x,y,level){
  indata1=indata[c(x,y)]

  names(indata1)=c("x","y")

  if(level %in% indata1$x & level %in% indata1$y){
    indata1=indata1 %>% dplyr::mutate(x1=ifelse(x==level,1,0),y1=ifelse(y==level,1,0))

    conf_matrix = table(indata1$x1, indata1$y1)

    df_out=data.frame(
      x=x,y=y,level=level,
      sensitivity = conf_matrix[2,2] / sum(conf_matrix[2,]),
      specificity = conf_matrix[1,1] / sum(conf_matrix[1,])
    )
  }

  if(!(level %in% indata1$x & level %in% indata1$y)){
    df_out=data.frame(
      x=x,y=y,level=level,
      sensitivity = NA,      specificity = NA
    )
  }


  df_out
}

#Col data -------------------
update_colData=function(obj_in,df_col){
  if(!all(colnames(obj_in$SE)==row.names(df_col))){stop("Row names of df_col not equal to column names of object")} else {
    
    df_col_old=as.data.frame(colData(obj_in$SE))
    
    names_overlap=names(df_col_old)[names(df_col_old) %in% names(df_col)]
    message(paste0("Will update ",length(names_overlap)," variable names: ",paste0(names_overlap,collapse = ",")))
    
    names_new=names(df_col)[!names(df_col) %in% names(df_col_old)]
    message(paste0("Will add ",length(names_new)," variable(s): ",paste0(names_new,collapse = ",")))
    
    for(name in c(names_overlap,names_new)){
      obj_in$SE[[name]]=NULL
      obj_in$SE[[name]]=unlist(df_col[name])
    }
  }
  obj_in
}


# Batch correction -------------------

correct_batch_var=function(obj_in,batch_var,assay_name_in="vst"){

  cat(paste0("running batch correction for ",batch_var,"\n"))
  
  df_col=colData(obj_in$SE) %>% as.data.frame()
  
  if(!batch_var %in% names(df_col)){stop(paste0(batch_var," not in col data"))}

  batch_value=unlist(df_col[batch_var])

  matrix_=apply(assays(obj_in$SE)[[assay_name_in]],2,as.numeric)

  df_out = sva::ComBat(dat=matrix_, batch=batch_value, par.prior=TRUE) %>%
    as.data.frame() %>% round(., digits = 8)
  row.names(df_out)=row.names(rowData(obj_in$SE))

  cat(paste0("outdata dim: ", paste0(dim(df_out),collapse = ","),"\n"))

  #get new SE
  # matrix_list=list()
  # matrix_list$matrix_=df_out
  # names(matrix_list)=assay_name_in
  # SE=SummarizedExperiment(matrix_list, colData = colData(obj_in$SE))

  #get new obj
  obj_out=obj_in
  assays(obj_out$SE)[[assay_name_in]]=df_out
  
  cat("Done\n")
  obj_out
}


# Matrix processing -------------------

get_topMAD_features=function(df_in,N_genes){
  geneMadOrd = names(sort(apply(df_in,1,mad),decreasing = T))
  if(length(geneMadOrd)>N_genes){topMadGenes=geneMadOrd[1:N_genes]}
  if(length(geneMadOrd)<=N_genes){topMadGenes=geneMadOrd}
  topMadGenes
}

get_variable_genes=function(obj_in,N_genes,method="MAD",assay_name_in="vst"){
  if(tolower(method)=="mad"){
    get_topMAD_features(assays(obj_in$SE)[[assay_name_in]],N_genes)
  }
}

get_nonCorr_genes=function(obj_in,
                           feature_panel=NULL,
                           featureRank=NULL,
                           highCorrCutoff=0.75,
                           iteration_times=NULL,
                           assay_name_in="vst"){
  #get input matrix
  if(is.null(feature_panel)){
    indata=assays(obj_in$SE)[[assay_name_in]]
    }

  if(!is.null(feature_panel)){
    indata=assays(obj_in$SE)[[assay_name_in]];
    inlist=obj_in[[feature_panel]]
    indata=indata[inlist,]
    }

  if(is.null(featureRank)){
    #run corr
    set.seed(10)
    modelDF=t(indata) %>% as.data.frame()
    cat("Calculating correlation...\n")
    corrMatrix = cor(modelDF)
    highCorrIdx = caret::findCorrelation(corrMatrix, cutoff=highCorrCutoff)
    highCorrGenes=colnames(modelDF[, highCorrIdx])

    #output
    if(is.null(feature_panel)){
      out_list=row.names(rowData(obj_in$SE))[!row.names(rowData(obj_in$SE)) %in% highCorrGenes]}

    if(!is.null(feature_panel)){
      inlist=obj_in[[feature_panel]]
      out_list=inlist[!inlist %in% highCorrGenes]
    }
  }

  if(!is.null(featureRank)){
    if(!length(featureRank)==length(inlist)){"Length of features and feature ranks not match"}

    df_feature=data.frame(feature=inlist,rank=featureRank,stringsAsFactors = F)

    set.seed(10)
    modelDF=t(indata) %>% as.data.frame()
    corrMatrix = cor(modelDF) %>% reshape2::melt() %>% filter(!Var1==Var2)

    if(max(corrMatrix$value) >= highCorrCutoff){
      message("Run correlation iteration")

      data_loop=indata
      corrMatrix_loop=corrMatrix
      i=1
      remove_ids=NULL
      in_list_=inlist

      while(max(corrMatrix_loop$value) >= highCorrCutoff){
        cat(paste0("Interations: ",i,"\n"))

        corrMatrix_loop1=corrMatrix_loop %>% filter(!Var1==Var2) %>%
          filter(value >= highCorrCutoff) %>%
          filter(!Var1==Var2) %>%
          left_join(df_feature %>% transmute(Var1=feature,rank1=rank)) %>%
          left_join(df_feature %>% transmute(Var2=feature,rank2=rank)) %>%
          dplyr::mutate(keep_id=ifelse(rank1<rank2,Var1,
                                ifelse(rank1>rank2,Var2,NA)))

        corrMatrix_loop1$keep_id[is.na(corrMatrix_loop1$keep_id)]=
          apply(corrMatrix_loop1[is.na(corrMatrix_loop1$keep_id),], 1, function(x){sort(c(unlist(x[1]),unlist(x[2])))[1]})

        remove_ids_=unique(c(corrMatrix_loop1$Var1,corrMatrix_loop1$Var2))
        remove_ids_=remove_ids_[!remove_ids_ %in% corrMatrix_loop1$keep_id]
        cat(paste0("\nRemoved ids: ",paste0(remove_ids_,collapse = ","),"\n"))
        remove_ids=unique(c(remove_ids,remove_ids_))

        in_list_=in_list_[!in_list_ %in% remove_ids]

        data_loop=data_loop[in_list_,]

        corrMatrix_loop = as.data.frame(t(data_loop)) %>% cor() %>% reshape2::melt() %>% filter(!Var1==Var2)
        i=i+1
        cat(paste0("Number of removed features: ",length(remove_ids),"\n"))
        if(!is.null(iteration_times)){if((i-1)>=iteration_times){break}}
      }
      out_list=inlist[!inlist %in% remove_ids]

    } else {
      message("No high correlation in matrix, output the input list")
      out_list=inlist
    }

  }

  out_list
}

remove_lowexpression_genes=function(obj_in,assay_name_in="vst",cutoff=5){
  indata=as.matrix(assays(obj_in$SE)[[assay_name_in]])
  out_data=indata[apply(indata, 1, max) >= cutoff,]
  obj_in$SE=obj_in$SE[row.names(out_data),]
  obj_in
}

get_Matrix=function(obj_in,assay_name_in=NULL,features=NULL,reduction=NULL,dims=1:50){
  if(!is.null(assay_name_in)){
    #get feature names --
    if(!is.null(features)){}
    if(is.null(features)){features=rownames(obj_in1$SE)}

    #get matrix --
    matrix_=as.matrix(assays(obj_in$SE)[[assay_name_in]])
    matrix_=matrix_[features,]
    matrix_=t(matrix_)
    print(paste0("Input N(samples),N(features): ",paste0(dim(matrix_),collapse = ",")))

  }

  if((!is.null(reduction)) & (!is.null(dims))){
    #get count matrix --
    matrix_=obj_in[[reduction]]
    matrix_=matrix_[dims]
    print(paste0("Input N(samples),N(features): ",paste0(dim(matrix_),collapse = ",")))
  }
  matrix_
}

get_features_df=function(obj_in,assay_name_in="vst",features="cluster_Phenograph_pca1"){
  features1=features[features %in% names(colData(obj_in$SE))]
  if(length(features1) >=1){
    df_feature1=as.data.frame(colData(obj_in$SE)[features1])
    df_feature=df_feature1
  }

  features2=features[features %in% rownames(obj_in$SE)]
  if(length(features2) >=1){
    df_feature2=as.data.frame(t(assays(obj_in$SE[features2,])[[assay_name_in]]))
    df_feature=df_feature2
  }

  if(length(features1) >=1 & length(features2) >=1){
    if(!all(row.names(df_feature1)==row.names(df_feature2))){stop("df feature rownames not match")}
    df_feature=bind_cols(df_feature1,df_feature2)
  }

  df_feature
}


get_embeding_feature=function(obj_in,assay_name_in="vst",features="cluster_Phenograph_pca1",reduction="tsne"){
  if(!all(row.names(colData(obj_in$SE))==row.names(obj_in[reduction]))){stop("Sample names in colData and reduction not match")}

  df_feature=get_features_df(obj_in = obj_in,assay_name_in = assay_name_in,features = features)

  df_reduction=obj_in[[reduction]]
  df_out=bind_cols(df_feature,df_reduction)

  df_out
}

#Obj processing -------------------
# obj_in=obj_2042_mini
# df_in=df_vst_test
obj_merge=function(obj_in=NULL,file_obj=NULL,df_in,assay_name_in="vst"){
  if(!is.null(file_obj)){
    obj_in=readRDS(file_obj)
  }

  #check name overlapping
  if(names(df_in)[2] %in% colnames(obj_in$SE)){
    obj_in$SE=obj_in$SE[,-match(names(df_in)[2],colnames(obj_in$SE))]
  }

  #get obj count data
  count_ref=assays(obj_in$SE)[[assay_name_in]]
  count_ref=as.data.frame(count_ref)
  count_ref$feature=row.names(count_ref)

  #get merged count data

  if(!any(grepl("feature",names(df_in)))){df_in$feature=row.names(df_in)}

  features_overlap=df_in$feature[df_in$feature %in% row.names(count_ref)]
  count_merge=df_in %>% left_join(count_ref) %>%
    filter(feature %in% features_overlap)
  row.names(count_merge)=count_merge$feature
  count_merge$feature=NULL

  #get info data
  df_info_ref=as.data.frame(colData(obj_in$SE))
  df_info_in=data.frame(
    id=names(df_in)[2:ncol(df_in)],
    diag="TestSample",
    diag_raw="TestSample",
    library="Unknown"
  )

  row.names(df_info_in)=names(df_in)[2:ncol(df_in)]

  df_info_all=bind_rows(df_info_in,df_info_ref)[c("diag","diag_raw")]

    #get output obj
  if(all(names(count_merge)==row.names(df_info_all))){
    matrix_list=list(counts=count_merge)
    names(matrix_list)=assay_name_in
    SE=SummarizedExperiment(assays=matrix_list, colData = df_info_all)
    obj_out=obj_in
    obj_out$SE=SE
  }

  if(!all(names(count_merge)==row.names(df_info_all))){
    stop("Names not match")
  }
  obj_out
}



#Normalization --------------------
run_normalization=function(){}

#' run_vst
#'
#' @param obj_in
#' @param assay_name_in
#' @param assay_name_out
#' @param var_design
#'
#' @return
#' @export
#'
#' @examples
# add_constant=1L
run_vst=function(obj_in,assay_name_in="counts",assay_name_out="vst",var_design=NULL,add_constant=NULL){
  matrix_=as.matrix(assays(obj_in$SE)[[assay_name_in]])
  df_colData=as.data.frame(as.matrix(colData(obj_in$SE)))
  
  if(!is.null(var_design)){formula_in=formula(paste0("~",paste0(var_design,collapse = "+")))}
  if(is.null(var_design)){formula_in=formula(paste0("~","1"))}
  
  obj_deseq2 = DESeq2::DESeqDataSetFromMatrix(countData = matrix_,colData = df_colData,design = formula_in)
  cat("Running vst\n")
  
  if(!is.null(add_constant)){
    dds <- estimateSizeFactors(obj_deseq2)
    counts(dds) <- counts(dds) + add_constant
    vst_data <- DESeq2::vst(dds, blind = FALSE)
    df_vst=round(as.matrix(assay(vst_data)),6)
  }
  
  if(is.null(add_constant)){
    obj_deseq2=DESeq2::varianceStabilizingTransformation(obj_deseq2,blind = T)
    df_vst=round(as.matrix(assay(obj_deseq2)),6)
  }
  
  assays(obj_in$SE)[[assay_name_out]]=df_vst
  cat("Done vst running\n")
  obj_in
}



#df_matrix_CPM=as.data.frame(DGEobj.utils::convertCounts(countsMatrix = as.matrix(df_matrix1),unit = "CPM"))

run_vst_matrix_df=function(df_in){

  df_colData=as.data.frame(data.frame(sampleid=colnames(df_in),stringsAsFactors = F) %>%
                             dplyr::mutate(obs=1:n()))
  row.names(df_colData)=df_colData$sampleid
  df_colData$sampleid=NULL
  formula_in=formula("~obs")

  obj_ = DESeq2::DESeqDataSetFromMatrix(countData = df_in,
                                        colData = df_colData,
                                        design = formula_in)


  obj_vst=DESeq2::varianceStabilizingTransformation(obj_,blind = T)

  df_vst=data.frame(round(assay(obj_vst),8))
  df_vst
}

get_vst_values=function(obj_in=NULL,file_obj=NULL,df_count=df_count){

  obj_x=obj_merge(obj_in=obj_in,file_obj = file_obj,df_in = df_count)

  obj_x=run_vst(obj_in = obj_x)

  df_vst=as.data.frame(assays(obj_x$SE)[["vst"]])
  df_vst$feature=row.names(df_vst)

  df_vst_out=df_vst[c("feature",names(df_count)[2:ncol(df_count)])] %>% arrange(feature)

  df_vst_out
}

cal_tpm=function(count_matrix,df_length){
  
  count_matrix1=count_matrix %>% 
    filter(feature %in% df_length$feature) %>% 
    left_join(df_length)
  
  count_matrix2=count_matrix1 %>% 
    reshape2::melt(id.vars=c("feature","length")) %>% 
    dplyr::mutate(lenth.k=length/1000,
           RPK=value/lenth.k) %>% 
    group_by(variable) %>% 
    dplyr::mutate(perMillionScalingFactor=sum(RPK)/1000000) %>% 
    ungroup() %>% dplyr::mutate(TPM=RPK/perMillionScalingFactor) %>% 
    dplyr::select(feature,variable,TPM) %>% 
    tidyr::spread(variable,TPM)
  
  count_matrix2
}


# Scale data ---------------------
run_scaling=function(){}

# Get markers (DE etc) ------------------
# obj_in=obj_319_coding
# features=gene_in[1:100]
# var_effect="disease"
# test_level="HCM"
# control_level="Control"
# var_adj="NULL"
# assay_name_in="counts"
# 
# table(df_colData$diag_granular==test_level)

run_DE_DESeq2=function(obj_in,features=NULL,var_effect,test_level,control_level=NULL,var_adj="NULL",assay_name_in="counts",
                       fold_change_shrinkage=F,
                       fold_change_shrinkage_method='apeglm'){
  #get col data --
  obj_in1=obj_in
  df_colData=as.data.frame(as.matrix(colData(obj_in$SE)))

  df_colData=df_colData[!is.na(unlist(df_colData[var_effect])),]

  if(!is.null(control_level)){if(control_level=="NULL"){control_level=NULL}}
  
  if(is.null(control_level)){
    df_colData$var_effect=ifelse(unlist(df_colData[var_effect])==test_level,test_level,"0others")
  }

  if(!is.null(control_level)){
    df_colData=df_colData[unlist(df_colData[var_effect]) %in% c(test_level,control_level),]
    df_colData$var_effect=unlist(df_colData[var_effect])
  }

  obj_in1$SE=obj_in1$SE[,row.names(df_colData)]

  #get feature names --
  if(!is.null(features)){}
  if(is.null(features)){features=rownames(obj_in1$SE)}

  #get count matrix --
  matrix_=as.matrix(assays(obj_in1$SE)[[assay_name_in]])

  #get formula --
  if(var_adj=="NULL"){var_adj=""}

  if(!(var_adj=="" | is.na(var_adj))){
    formula_in=formula(paste0("~",paste0(c('var_effect',var_adj),collapse = "+")))
  }

  if(var_adj=="" | is.na(var_adj)){
    formula_in=formula(paste0("~",paste0('var_effect',collapse = "+")))
  }
  
  print(paste0("Samples N in DE =",ncol(matrix_)))
  print(paste0("Features N in DE =",nrow(matrix_)))
  print(paste0("Design formula: ",formula_in))

  print("get Deseq2 obj")
  obj_deseq2 = DESeq2::DESeqDataSetFromMatrix(countData = matrix_,
                                              colData = df_colData,
                                              design = formula_in)
  #Running DE --
  print("Running DE")
  dds = DESeq2::DESeq(obj_deseq2)

  if(is.null(control_level)){
    res=DESeq2::results(dds, contrast=c('var_effect',test_level,"0others"))
    if(fold_change_shrinkage){
      message(paste0("Running fold_change_shrinkage using ",fold_change_shrinkage_method," method"))
      res <- DESeq2::lfcShrink(dds, coef=paste0('var_effect',"_",gsub("-","_",test_level),"_vs_","0others"), type=fold_change_shrinkage_method)
    }
  }

  if(!is.null(control_level)){
    res=DESeq2::results(dds, contrast=c('var_effect',test_level,control_level))
    
    if(fold_change_shrinkage){
      message(paste0("Running fold_change_shrinkage using ",fold_change_shrinkage_method," method"))
      res <- DESeq2::lfcShrink(dds, coef=paste0('var_effect',"_",gsub("-","_",test_level),"_vs_",control_level), type=fold_change_shrinkage_method)
    }
  }
  

  res_DE=as.data.frame(res@listData) %>%
    dplyr::mutate(feature=res@rownames,
           test=
             ifelse(is.null(control_level),paste0(test_level,"_vs_","others"),paste0(test_level,"_vs_",control_level))
             ) %>%
    arrange(padj)

  row.names(res_DE)=res_DE$feature

  print("Done")
  res_DE
}

run_DE_edgeR=function(obj_in,features=NULL,var_effect,test_level,control_level="NULL",var_adj="NULL",assay_name_in="counts"){
  message(paste0("TestLevel=",test_level,"; ControlLevel=",control_level))
  #get col data --
  df_colData=as.data.frame(as.matrix(colData(obj_in$SE)))
  
  df_colData=df_colData[!is.na(unlist(df_colData[var_effect])),]
  
  if(!is.null(control_level)){if(control_level=="NULL"){control_level=NULL}}
  
  if(is.null(control_level)){
    df_colData$var_effect=ifelse(unlist(df_colData[var_effect])==test_level,test_level,"others")
  }
  
  if(!is.null(control_level)){
    df_colData=df_colData[unlist(df_colData[var_effect]) %in% c(test_level,control_level),]
    df_colData$var_effect=unlist(df_colData[var_effect])
  }
  
  #get filtered object --
  obj_in1=obj_in
  obj_in1$SE=obj_in1$SE[,row.names(df_colData)]
  
  #get feature names --
  if(!is.null(features)){}
  if(is.null(features)){features=rownames(obj_in1$SE)}
  
  #get count matrix --
  matrix_=as.matrix(assays(obj_in1$SE)[[assay_name_in]])
  print(dim(matrix_))
  
  #get formula --
  if(var_adj=="NULL"){var_adj=""}
  
  if(!(var_adj=="" | is.na(var_adj))){
    formula_in=formula(paste0("~0+",paste0(c('var_effect',var_adj),collapse = "+")))
  }
  
  if(var_adj=="" | is.na(var_adj)){
    formula_in=formula(paste0("~0+",paste0('var_effect',collapse = "+")))
  }
  
  #get csaw obj --
  obj_csaw=csaw::asDGEList(obj_in1$SE)
  colnames(obj_csaw) = colnames(obj_in1$SE)
  rownames(obj_csaw) = as.character(row.names(x=obj_in1$SE))
  
  #get desing
  design = model.matrix(formula_in, data=df_colData)
  # if(is.null(control_level)){colnames(design)[1:2]=c("others",test_level)}
  colnames(design)= gsub("var_effect","",colnames(design))
  
  #run DE --
  message("\n")
  message("Running DE ...\n")
  out_estimateDisp = edgeR::estimateDisp(obj_csaw, design=design)
  out_glmQLFit = edgeR::glmQLFit(out_estimateDisp, design)

  if(!is.null(control_level)){  formula_str=paste0(test_level,"-",control_level)}
  if(is.null(control_level)){   formula_str=paste0(test_level,"-","others")}
    
  contrast <- eval(parse(text = paste0("makeContrasts(", formula_str, ", levels = colnames(design))")))
  # print(contrast)
    
  out_glmQLFTest = glmQLFTest(out_glmQLFit, contrast = contrast[,1])
  
  df_DE = topTags(out_glmQLFTest, n=Inf, sort.by="none")$table %>% 
    as.data.frame() %>% arrange(PValue)
  
  df_feature=data.frame(feature=row.names(df_DE),stringsAsFactors = F)
  df_feature$contrast=ifelse(is.null(control_level),paste0(test_level," vs others"),paste0(test_level," vs ",control_level))
  
  df_DE=bind_cols(df_feature,df_DE) %>% 
    mutate(
      P.adj.hochberg=p.adjust(PValue,method ="hochberg"),
      P.adj.bonferroni=p.adjust(PValue,method ="bonferroni"),
      logP=-log(PValue,10),
      logP.fdr=-log(FDR,10),
      logP.hochberg=-log(P.adj.hochberg,10),
      logP.bonferroni=-log(P.adj.bonferroni,10)
    )
  
  cat("Done\n")
  df_DE
}


DE_wilcoxon_one=function(df_for_analysis,var_x,control_level,test_level,var_y){

  df_for_analysis1=df_for_analysis[c(var_x,var_y)]
  names(df_for_analysis1)=c("var_x","var_y")
  df_for_analysis1=df_for_analysis1 %>% filter(var_x %in% c(control_level,test_level))

  df_mean=df_for_analysis1 %>% group_by(var_x) %>% dplyr::mutate(mean=round(mean(var_y),4)) %>% dplyr::select(var_x,mean) %>% distinct()

  df_out=data.frame(
    var_x=var_x,
    control_level=control_level,
    test_level=test_level,
    feature=var_y,
    mean_control=df_mean$mean[df_mean$var_x==control_level],
    mean_test=df_mean$mean[df_mean$var_x==test_level],
    fold_change=round(df_mean$mean[df_mean$var_x==test_level]/df_mean$mean[df_mean$var_x==control_level],4),
    log2fold_change=log2(round(df_mean$mean[df_mean$var_x==test_level]/df_mean$mean[df_mean$var_x==control_level],4)),
    P=wilcox.test(var_y~var_x,data=df_for_analysis1)$p.value,
    stringsAsFactors = F
  )
  df_out
}

run_DE_wilcoxon=function(obj_in,features=NULL,var_effect="diag",test_level=c("TCF3-PBX1","ETV6-RUNX1"),
                         control_level="Other",var_adj,assay_name_in="vst"){
  df_colData=as.data.frame(as.matrix(colData(obj_in$SE)))

  value_effect=unlist(df_colData[var_effect])

  df_colData1=df_colData %>% filter(value_effect %in% c(test_level,control_level))
  df_colData1$id=row.names(df_colData1)

  obj_in1=obj_in

  obj_in1$SE=obj_in1$SE[,row.names(df_colData1)]

  df_=as.data.frame(t(as.matrix(assays(obj_in1$SE)[[assay_name_in]])))

  if(!is.null(features)){}
  if(is.null(features)){features=rownames(obj_in1$SE)}


  df_$id=row.names(df_)
  df_for_analysis=df_colData1 %>% left_join(df_)

  test_level_one=test_level[1]

  df_out=
    bind_rows(lapply(test_level, function(test_level_one){
      df_out=bind_rows(lapply(features,function(var_y){
        DE_wilcoxon_one(df_for_analysis,var_x=var_effect,control_level=control_level,test_level=test_level_one,var_y=var_y)
      }))
      df_out$P_fdr=p.adjust(df_out$P,method = "fdr")
      df_out
    }))
  df_out
}

run_DE_bulkRNA=function(obj_in,features=NULL,var_effect="diag",test_level=c("TCF3-PBX1"),
                        control_level="Other",var_adj,assay_name_in="vst",method){

  if(!tolower(method) %in% c("wilcoxon","deseq2")){stop("Method not defined")}

  if(tolower(method)=="wilcoxon"){
    df_out=run_DE_wilcoxon(obj_in=obj_in,features=features,var_effect=var_effect,test_level=test_level,
                           control_level=control_level,var_adj=var_adj,assay_name_in=assay_name_in)
  }


  if(tolower(method)=="deseq2"){
    df_out=run_DE_DESeq2(obj_in,
                         features=features,
                         var_effect=var_effect,
                         test_level=test_level,
                         control_level=control_level,
                         var_adj=var_adj,
                         assay_name_in=assay_name_in)

  }

  df_out

}


get_markers=function(){}

#DE stats ------------------------------
get_sigDE=function(df_in,var_FC="logFC",var_P="FDR",cutoff_FC=1,cutoff_P=0.05){
  df_sig=df_in[df_in[var_P]<cutoff_P & abs(df_in[var_FC])>cutoff_FC,]
  df_sig$change=ifelse(df_sig[var_FC] < -FC_cutoff,"downReg",ifelse(df_sig[var_FC] > FC_cutoff,"upReg","no_change"))
  print(table(df_sig$change))
  df_sig
}

#Dimension reductions ---------------
run_PCA=function(obj_in,dims=100,variable_n=800,feature_panel="TopMAD5000",out_label="pca",assay_name_in="vst"){

  variable_genes_in=obj_in[[feature_panel]][1:min(length(obj_in[[feature_panel]]),variable_n)]
  
  indata=assays(obj_in$SE[variable_genes_in,])[[assay_name_in]]
  
  cat("Run tSNE: Used Feature N=", dim(indata)[1], "; Used Sample N=", dim(indata)[2], "\n")
  
  pca_fit=prcomp(indata, rank = dims)
  df_pc=data.frame(round(pca_fit$rotation,8))

  row.names(df_pc)=colnames(obj_in$SE)

  obj_in[[out_label]]=df_pc
  obj_in
}


# obj_in=obj_out
# feature_panel="boruta_genes"
# obj_$boruta_genes

run_tsne=function(obj_in,perplexity_one=30,dims=2,variable_n=800,out_label="tsne",feature_panel="variable_genes",assay_name_in="vst",initial_dims=50){
  variable_genes_in=obj_in[[feature_panel]][1:min(variable_n,length((obj_in[[feature_panel]])))]

  indata=assays(obj_in$SE[variable_genes_in,])[[assay_name_in]]
  indata1=t(indata)
  cat("Run tSNE: Used Feature N=", dim(indata1)[2], "; Used Sample N=", dim(indata1)[1],"; Perplexity=", perplexity_one,  "\n")

  set.seed(10) # Sets seed for reproducibility
  tsne_out = Rtsne(indata1, dims = dims, perplexity = perplexity_one,
                   theta = 0.5,
                   initial_dims =initial_dims,
                   max_iter = 5000,
                   check_duplicates = F,
                   partial_pca=T,
                   num_threads = 4)

  #summary output
  df_id=data.frame(COH_sample=colnames(indata))

  df_tsne=as.data.frame(tsne_out$Y)
  names(df_tsne)=c("tSNE_1","tSNE_2","tSNE_3")[1:ncol(df_tsne)]

  df_tsne$perplexityN=perplexity_one
  df_tsne$FeatureN=dim(indata1)[2]

  # names(df_tsne)=paste0(names(df_tsne),"_FeatureN",dim(indata1)[2],"_PerplexityN",perplexity_one)

  row.names(df_tsne)=colnames(indata)
  df_tsne$COH_sample=row.names(df_tsne)

  obj_in[[out_label]]=df_tsne
  obj_in
}

run_umap=function(obj_in,n_neighbors=10,dims=2,variable_n=800,out_label="umap",feature_panel="variable_genes",assay_name_in="vst",pca_usedDims=50,min_dist=0.25){

  if(!tolower(feature_panel) %in% c("pca")){
    #get features
    variable_genes_in=obj_in[[feature_panel]][1:min(variable_n,length((obj_in[[feature_panel]])))]

    #get running data
    indata=assays(obj_in$SE[variable_genes_in,])[[assay_name_in]]
    indata1=t(indata)
  } else if(tolower(feature_panel)=="pca"){
    pca_dims_max=min(ncol(obj_in$pca),pca_usedDims)
    indata=obj_in$pca[1:pca_dims_max]
    indata1=indata
  } else {
    stop("Feature Panel Not Found")
  }

  cat("Running uMAP: Feature N=", dim(indata1)[2], "; Sample N=", dim(indata1)[1],"; n_neighbors=", n_neighbors,  "\n")

  #running umap
  set.seed(100)
  fit_umap=umap::umap(indata1,n_neighbors=n_neighbors,random_state=456,n_components=dims,min_dist = min_dist)

  #get output
  df_umap=as.data.frame(fit_umap$layout)
  names(df_umap)=c("uMAP_1","uMAP_2","uMAP_3")[1:ncol(df_umap)]
  df_umap$n_neighbors=n_neighbors
  df_umap$FeatureN=dim(indata1)[2]
  df_umap$COH_sample=row.names(df_umap)

  #summary output
  obj_in[[out_label]]=df_umap
  obj_in[[paste0(out_label,"_fit")]]=fit_umap

  obj_in
}


#Clustering ------------------------
get_neighbors=function(){}

get_clusters=function(obj_in,assay_name_in=NULL,features=NULL,reduction=NULL,dims=1:50,
                      method="phenograph",Neighbor_k=5,
                      out_label="Phenograph"){
  df_in=get_Matrix(obj_in=obj_in,assay_name_in = assay_name_in,features = features, reduction = reduction,dims=dims)

  cat("\n")
  if(tolower(method)=="phenograph"){
    df_cluster=run_phenograph(df_in,Neighbor_k=Neighbor_k)
    if(!all(colnames(obj_in$SE)==row.names(df_cluster))){stop("Sample names in obj not consistent with rownames of df cluster")}
    obj_in$SE[[paste0("cluster_",out_label)]]=df_cluster$cluster_Phenograph
  }
  obj_in
}

#Phenograph --------------------------


# run_phenograph=function(df_in,Neighbor_k=5){
#   cat("Run Phenograph: Used Feature N=", dim(df_in)[2], "; Used Sample N=", dim(df_in)[1],"; Neighbor_k=", Neighbor_k,  "\n")
#
#   print("Running Phenograph ...........................")
#   set.seed(10)
#   PG_out=Rphenograph(df_in, Neighbor_k)
#   cat("\n")
#   #get cluster ---
#   df_cluster=data.frame(id=row.names(df_in),stringsAsFactors = F) %>% dplyr::mutate(obs=1:n()) %>%
#     left_join(
#       data.frame(
#         obs=as.numeric(names(membership(PG_out[[2]]))),
#         cluster_Phenograph=as.vector(membership(PG_out[[2]])),
#         stringsAsFactors = F
#       )
#     ) %>%
#     dplyr::mutate(missing_cluster=ifelse(is.na(cluster_Phenograph),"MissingCluster","NotMissingCluster"))
#   cat("\n")
#   print(paste0("MissingCluster N= ",length(df_cluster$missing_cluster[df_cluster$missing_cluster=="MissingCluster"])))
#
#   row.names(df_cluster)=df_cluster$id
#   df_cluster["cluster_Phenograph"]
# }

run_PhenoGraph=function(obj_in,
                        feature_panel="variable_genes",
                        variable_n = 500,
                        neighbor_k=3,
                        ratio_cutoff=0.5,
                        out_label="PhenographPred"){

  library(Rphenograph)
  # library(igraph);library(RANN)
  # source("/home/zgu_labs/bin/R/RNAseq/Phenograph/Rphenograph/R/phenograph.R")
  # source("/home/zgu_labs/bin/R/RNAseq/Phenograph/Rphenograph/R/RcppExports.R")
  #
  
  print(feature_panel)
  print(length(obj_in[[feature_panel]]))

  variable_genes_in=obj_in[[feature_panel]][1:min(variable_n,length((obj_in[[feature_panel]])))]
  indata=assays(obj_in$SE[variable_genes_in,])[["vst"]]
  variable_n_real=length(variable_genes_in)
  indata1=t(indata)
  cat("Run Phenograph: Used Feature N=", dim(indata1)[2], "; Used Sample N=", dim(indata1)[1],"; Neighbor_k=", neighbor_k,  "\n")

  df_diag_match=data.frame(COH_sample=row.names(indata1),diag=obj_in$SE$diag,stringsAsFactors = F) %>% dplyr::mutate(obs=1:n())

  set.seed(10)
  PG_out=Rphenograph(indata1, neighbor_k)

  df_cluster=data.frame(
    obs=as.numeric(names(membership(PG_out[[2]]))),
    cluster=as.vector(membership(PG_out[[2]])),
    stringsAsFactors = F
  )

  df_cluster_detail=df_diag_match %>% left_join(df_cluster) %>%
    group_by(diag, cluster) %>% dplyr::mutate(N_diagCluster=n()) %>%
    group_by(cluster) %>%  dplyr::mutate(N_cluster=n()) %>%
    dplyr::mutate(ratio = round(N_diagCluster/N_cluster, digits = 2)) %>%
    arrange(cluster, desc(N_cluster))

  df_cluster_diag=df_cluster_detail %>% dplyr::select(diag,cluster,ratio,N_cluster,N_diagCluster,) %>% distinct() %>%
    filter(ratio>ratio_cutoff) %>% group_by(diag) %>% arrange(desc(N_diagCluster)) %>%
    dplyr::mutate(diag_pred=ifelse(!is.na(cluster),diag,"NoClusterAsigned"),
           diagCluster_index=1:n(),
           diagCluster_index_max=n(),
           diag_pred_granular=ifelse(diagCluster_index_max==1,diag_pred,paste0(diag_pred,"_",diagCluster_index)),
           diag_pred_freq=paste0(diag_pred,"(",N_diagCluster,";",ratio*100,"%)"),
           diag_pred_granular_freq=paste0(diag_pred_granular,"(",N_diagCluster,";",ratio*100,"%)"),
    ) %>% dplyr::select(diag,cluster,diag_pred,diag_pred_freq,diag_pred_granular,diag_pred_granular_freq)

  df_cluster_diag$diag=NULL

  df_diag_pred=df_cluster_detail %>%
    left_join(df_cluster_diag %>% dplyr::mutate(ratio=NULL)) %>%
    dplyr::mutate(obs=NULL,FeatureN=variable_n_real,top_neighborN=neighbor_k)

  df_diag_pred$diag_pred=ifelse(is.na(df_diag_pred$cluster),"NoClusterAsigned",df_diag_pred$diag_pred)
  df_diag_pred$diag_pred_freq=ifelse(is.na(df_diag_pred$cluster),"NoClusterAsigned",df_diag_pred$diag_pred_freq)
  df_diag_pred$diag_pred_granular=ifelse(is.na(df_diag_pred$cluster),"NoClusterAsigned",df_diag_pred$diag_pred_granular)
  df_diag_pred$diag_pred_granular_freq=ifelse(is.na(df_diag_pred$cluster),"NoClusterAsigned",df_diag_pred$diag_pred_granular_freq)

  df_diag_pred$diag_pred=ifelse(is.na(df_diag_pred$diag_pred),"FailedPrediction",df_diag_pred$diag_pred)
  df_diag_pred$diag_pred_freq=ifelse(is.na(df_diag_pred$diag_pred_freq),"FailedPrediction",df_diag_pred$diag_pred_freq)
  df_diag_pred$diag_pred_granular=ifelse(is.na(df_diag_pred$diag_pred_granular),"FailedPrediction",df_diag_pred$diag_pred_granular)
  df_diag_pred$diag_pred_granular_freq=ifelse(is.na(df_diag_pred$diag_pred_granular_freq),"FailedPrediction",df_diag_pred$diag_pred_granular_freq)

  row.names(df_diag_pred)=df_diag_pred$COH_sample

  obj_in[[out_label]]=df_diag_pred
  obj_in
}

get_PhenoGraphPred=function(obj_in,panelName="PhenographPred",SampleLevel="TestSample",type="value"){
  df_phenograph=obj_in[[panelName]]
  df_out=df_phenograph[df_phenograph$COH_sample %in% c(SampleLevel),]

  value_out=paste0("PhenoGraph Clustering Labeled Subtype:",df_out$diag_pred,
                   " (FeatureN=",df_out$FeatureN,"; NeighborN=",df_out$top_neighborN,")")
  if(type=="value"){out=value_out}
  if(tolower(type) %in% c("df","dataframe")){out=df_out}
  out
}


#SVM --------------------------

fit_svm=function(){
  library(e1071)
}





#get_cibersort_ref --------------------------

#rows for exp are samples
#cols for exp are genes
#use non log values. prefer to use counts, and make the mixture file(sample expression file) to CPM
#df_celltye with two columns: id and celltype

# df_celltype=df_pheno
# df_exp=as.matrix(t(matrix_cpm))
get_cibersort_ref=function(df_exp,df_celltype,outfile_prefix){
  if(!dir.exists(dirname(outfile_prefix))){dir.create(dirname(outfile_prefix))}
  if(!all(row.names(df_exp)==df_celltype$id)){stop("Sample id not match")}

  #make phenotype class
  df_celltype1=df_celltype %>% arrange(celltype,id)
  celltype_list=unique(df_celltype1$celltype)

  df_phenotypeClass_t=bind_cols(lapply(celltype_list, function(celltype_one){
    df_one=df_celltype1 %>% dplyr::mutate(x=ifelse(celltype==celltype_one,1,2)) %>% dplyr::select(x)
    names(df_one)=celltype_one
    df_one
  }))

  df_phenotypeClass=bind_cols(
    data.frame(celltype=celltype_list,stringsAsFactors = F),
    as.data.frame(t(df_phenotypeClass_t))
  )

  #make reference sample
  df_exp1=df_exp[df_celltype1$id,]
  df_exp1=as.data.frame(apply(df_exp1, 2, as.character))
  row.names(df_exp1)=df_celltype1$id

  df_exp1_t=as.data.frame(t(df_exp1))

  all(colnames(df_exp1_t)==df_celltype1$id)

  df1=as.data.frame(t(data.frame(celltype=df_celltype1$celltype,stringsAsFactors = F)),stringsAsFactors = F)
  names(df1)=colnames(df_exp1_t)

  df_exp1_t1=bind_rows(df1,df_exp1_t)
  df_referenceSample=bind_cols(
    data.frame(gene=row.names(df_exp1_t1),stringsAsFactors = F),
    df_exp1_t1
  )

  write.table(df_referenceSample,file=paste0(outfile_prefix,"_referenceSample.txt"),row.names = F,col.names = F,quote = F,sep="\t")
  write.table(df_phenotypeClass,file=paste0(outfile_prefix,"_phenotypeClass.txt"),row.names = F,col.names = F,quote = F,sep="\t")

  return(list(df_referenceSample=df_referenceSample,df_phenotypeClass=df_phenotypeClass))
}


#cibersortx -----------------------
# obj_in=readRDS("/scratch/zuhu/project/zhaohuigu/human1M/out/integration_8samplesAll/selection_auto/within_top500/top_150/obj_keyCelltype_top150.rds")
# var_celltype="celltype"
# dir_out="/scratch/zuhu/project/zhaohuigu/human1M/out/integration_8samplesAll/selection_auto/within_top500/top_150/"
# label="top150"

get_cibersortxRef_from_obj=function(obj_in,var_celltype,dir_out,label){

  df_pheno=get_metadataVar(obj_in,var_celltype)
  names(df_pheno)=c("id","celltype")
  table(df_pheno$celltype)

  matrix_=round(as.matrix(GetAssayData(obj_in[["SCT"]],slot = "data")),4)

  if(all(colnames(matrix_)==df_pheno$id)){
    ref_cibersortx=get_cibersort_ref(as.matrix(t(matrix_)),df_pheno,paste0(dir_out,label))
  }


  if(!all(colnames(matrix_)==df_pheno$id)){
    print("EXP id not match with phenotype id")
  }

  DimPlot(obj_in,group.by = var_celltype,label = T,repel = T,cols=DiscretePalette(length(unique(unlist(df_pheno["celltype"])))))
  ggsave(paste0(dir_out,"umap_celltype_for_cibersortx_",label,".png"),width=12,height=10)
  ggsave(paste0(dir_out,"umap_celltype_for_cibersortx_",label,".pdf"),width=12,height=10)

}

read_cibersortxOut=function(file_csv){
  df_=read.csv(file_csv,stringsAsFactors = F)
  df_[c("P.value","Correlation","RMSE","Absolute.score..sig.score.")]=NULL
  names(df_)[1]="COH_sample"
  
  df_1=df_ %>% reshape2::melt(id.vars="COH_sample") %>% group_by(COH_sample) %>% 
    mutate(sum_=sum(value),per=round(value/sum_,6),sum_1=sum(per)) %>% 
    reshape2::dcast(COH_sample~variable,value.var = "per")
  
  df_1
}


# write GSEA files -------------------------------------------
# file_gct: gene expression file
# file_cls: CLS: Categorical (e.g tumor vs normal) class file format (*.cls)

write_gct_cls=function(obj_in,var_group="group",file_gct,file_cls){
  
  normalized_counts =assays(obj_in$SE)[["vst"]]
  
  gct_data <- data.frame(
    Name = rownames(normalized_counts),
    Description = rownames(normalized_counts),
    normalized_counts
  )
  
  cat("#1.2\n", file = file_gct)
  cat(nrow(gct_data), "\t", ncol(gct_data) - 2, "\n", file = file_gct, append = TRUE)
  write.table(gct_data, file = file_gct, sep = "\t", quote = FALSE, row.names = FALSE, col.names = TRUE, append = TRUE)
  
  value_group=colData(obj_in$SE)[[var_group]]
  
  conditions <- unique(value_group)
  num_samples <- length(value_group)
  num_classes <- length(conditions)
  
  # lines
  line1 <- paste(num_samples, num_classes, 1, sep = " ")
  line2 <- paste("#", paste(conditions, collapse = " "), sep = " ")
  line3 <- paste(value_group, collapse = " ")
  
  writeLines(c(line1, line2, line3), file_cls)
}

#KNN ----
knn_pred_one=function(indata,var_y,var_x,KNN_K=3){

  indata=indata %>% dplyr::mutate(obs=1:n())

  formula_in=formula(paste0(var_y,"~",paste0(var_x,collapse = "+")))

  df_freq=as.data.frame(table(unlist(indata[var_y]))) %>% arrange(Freq)

  if(min(df_freq$Freq)==1){
    #split data
    levels_1=as.character(df_freq$Var1[df_freq$Freq==1])
    indata_1=indata[unlist(indata[var_y]) %in% levels_1,]
    indata_rest=indata %>% filter(!obs %in% indata_1$obs)

    #get KNN model
    knnFit_rest = train(formula_in, data = indata_rest, method = "knn",
                        preProcess = c("center", "scale"),
                        tuneGrid = expand.grid(k = c(KNN_K)))

    #get KNN predicted value
    indata_rest$knn_pred=predict(knnFit_rest) %>% as.vector()
    indata_1$knn_pred=unlist(indata_1[var_y])
    df_knn=bind_rows(indata_rest,indata_1) %>% arrange(obs)

    if(!all(df_knn$obs==indata$obs)){stop("obs not match in original data and predicted dataset")}

    knn_pred=df_knn$knn_pred
  }

  if(min(df_freq$Freq)>1){
    knnFit = train(formula_in, data = indata, method = "knn",
                   preProcess = c("center", "scale"),
                   tuneGrid = expand.grid(k = c(KNN_K)))
    knn_pred=predict(knnFit) %>% as.vector()
  }

  knn_pred
}

#' get_subtype_final_old
#'
#' @param id
#' @param df_feateure_exp
#' @param df_out_phenograph
#' @param df_out_svm
#' @param out_mutation
#' @param chrom_n
#' @param CNV_label
#' @param fusion_fc
#' @param fusion_c
#'
#' @return
#' @export
#'
#' @examples
get_subtype_final_old=function(
  id,
  df_feateure_exp=df_feateure_exp,
  df_out_phenograph=df_out_phenograph,df_out_svm=df_out_svm,
  out_mutation=out_mutation,
  chrom_n=chrom_n,CNV_label=CNV_label,
  fusion_fc=fusion_fc,fusion_c=fusion_c){
  
  #Gene expression
  subtype_exp=NA
  if(df_feateure_exp$Expression[df_feateure_exp$Gene=="CRLF2"]>=9){subtype_exp="CRLF2"}
  if(df_feateure_exp$Expression[df_feateure_exp$Gene=="CDX2"]>=9){subtype_exp="CDX2/UBTF"}
  if(df_feateure_exp$Expression[df_feateure_exp$Gene=="NUTM1"]>=9.5){subtype_exp="NUTM1"}
  
  
  #CNV
  Chr21Alteration=ifelse(grepl("21",CNV_label),"Yes","No")
  
  if(chrom_n>=51){
    subtype_cnv="Hyperdiploid"
  } else if (chrom_n>=47) {
    subtype_cnv="Low hyperdiploid"
  } else if (chrom_n>=39) {
    subtype_cnv=NA
  } else if (chrom_n >=31) {
    subtype_cnv="Low hypodiploid"
  } else {
    subtype_cnv="Near haploid"
  }
  
  #fusion
  fusion_fc_top=fusion_fc %>% slice_head(n=2)
  fusion_c_top=fusion_c %>% slice_head(n=2)
  fusion_out=bind_rows(fusion_fc[-(2:3)],fusion_c[-(2:3)]) %>% distinct()
  
  
  #GEP
  gep_=NA;subtype_GEP_def=NA
  pg_=get_pred_result(df_out_phenograph)
  score_phenograph=get_pred_score(df_out_phenograph)
  subtype_phenograph_label=get_pred_label(df_out_phenograph)
  gp_all=df_out_phenograph$pred
  
  
  
  svm_=get_pred_result(df_out_svm)
  score_svm=get_pred_score(df_out_svm)
  subtype_svm_label=get_pred_label(df_out_svm)
  svm_all=df_out_svm$pred
  
  
  gep_all=sort(unique(c(gp_all,svm_all)))
  
  
  
  # pg_="y";svm_="x"
  if(pg_==svm_){gep_=svm_}
  if(!pg_==svm_){
    if(any(c(pg_,svm_) %in% fusion_out$PossibleSubtype)){
      gep_=c(pg_,svm_)[c(pg_,svm_) %in% fusion_out$PossibleSubtype]
    } else {
      if(all(c(svm_,pg_)=="Unclassified")){gep_="Unclassified"}
      else if ("Unclassified" %in% c(svm_,pg_)){
        gep_=c(svm_,pg_)[-match("Unclassified",c(svm_,pg_))]
      } else {
        gep_=c(svm_,pg_)
      }
    }
  }
  
  subtype_GEP=gep_
  
  if("ETV6::RUNX1" %in% subtype_GEP){gep_all=unique(c(gep_all,"ETV6::RUNX1-like"))}
  if("Ph" %in% subtype_GEP){gep_all=unique(c(gep_all,"Ph-like"))}
  
  if("ETV6::RUNX1" %in% subtype_GEP){subtype_GEP=unique(c(subtype_GEP,"ETV6::RUNX1-like"))}
  if("Ph" %in% subtype_GEP){subtype_GEP=unique(c(subtype_GEP,"Ph-like"))}
  
  #fusion sum
  fusion_fc_=NA;fusion_c_=NA;subtype_fusion_GEP=NA;subtype_fusion_alone=NA;df_fusion_fc=data.frame();df_fusion_c=data.frame()
  if(any(gep_all %in% c(fusion_fc$PossibleSubtype,fusion_c$PossibleSubtype))){
    
    if(any(gep_all %in% fusion_fc$PossibleSubtype)){
      df_fusion_fc=fusion_fc %>% filter(PossibleSubtype %in% gep_all) %>%
        arrange(desc(Spanning_unique_reads)) %>% slice_head(n=2) %>% arrange(FusionInFile)
      fusion_fc_=df_fusion_fc$FusionInFile
    }
    
    if(any(gep_all %in% fusion_c$PossibleSubtype)){
      df_fusion_c=fusion_c %>% filter(PossibleSubtype %in% gep_all) %>%
        arrange(desc(readsB)) %>% slice_head(n=2) %>% arrange(FusionInFile)
      fusion_c_=df_fusion_c$FusionInFile
    }
    
    df_fusion_=bind_rows(df_fusion_fc,df_fusion_c) %>%
      dplyr::select(FusionInFile,PossibleSubtype) %>% distinct() %>% arrange(FusionInFile)
    
    subtype_fusion_GEP=sort(unique(df_fusion_$PossibleSubtype))
    
  }
  
  if(!any(gep_all %in% c(fusion_fc$PossibleSubtype,fusion_c$PossibleSubtype))){
    
    fusion_def_subtypes=c("BCL2/MYC","MEF2D","CRLF2","ETV6::RUNX1","ETV6::RUNX1-like")
    
    df_fusion_out=fusion_out %>%
      group_by(method) %>% slice_head(n=2) %>% arrange(FusionInFile)
    
    fusion_fc_=df_fusion_out$FusionInFile[df_fusion_out$method=="fc"]
    fusion_c_=df_fusion_out$FusionInFile[df_fusion_out$method=="c"]
    
    subtype_fusion_alone=unique(df_fusion_out$PossibleSubtype)
  }
  
  #summarise ----
  subtype_final=NA;confidence="High"
  
  subtype_final=ifelse(any(subtype_GEP %in% subtype_exp),intersect(subtype_GEP,subtype_exp),NA)
  if(is.na(subtype_final)){if("Hyperdiploid" %in% gep_all & "Hyperdiploid" %in% subtype_cnv){subtype_final="Hyperdiploid"}}
  
  if(is.na(subtype_final)){subtype_final=ifelse(any(subtype_GEP %in% subtype_fusion_GEP),intersect(subtype_GEP,subtype_fusion_GEP),NA)}
  
  if(is.na(subtype_final)){if("iAMP21" %in% gep_all & Chr21Alteration=="Yes"){subtype_final="iAMP21"}}
  if(is.na(subtype_final)){if( "Near haploid" %in% subtype_cnv){subtype_final="Near haploid"}}
  if(is.na(subtype_final)){if( "Low hypodiploid" %in% subtype_cnv){subtype_final="Low hypodiploid"}}
  
  if(is.na(subtype_final)){subtype_final=ifelse(any(gep_all %in% subtype_fusion_GEP),intersect(gep_all,subtype_fusion_GEP),NA)}
  if(is.na(subtype_final)){subtype_final=ifelse(any(subtype_GEP %in% subtype_fusion_alone),intersect(subtype_GEP,subtype_fusion_alone),NA)}
  if(is.na(subtype_final)){subtype_final=ifelse(any(subtype_GEP %in% subtype_cnv),intersect(subtype_GEP,subtype_cnv),NA)}
  if(is.na(subtype_final)){subtype_final=ifelse(any(subtype_GEP %in% out_mutation$subtype_mutation),intersect(subtype_GEP,out_mutation$subtype_mutation),NA)}
  
  
  if(is.na(subtype_final)){
    if(svm_=="DUX4" & pg_=="DUX4" & score_phenograph==1 & score_svm==1){subtype_final="DUX4"}
  }
  
  if(is.na(subtype_final)){
    if(any(c('ETV6::RUNX1',"RUNX1::ETV6") %in% c(fusion_fc_,fusion_c_))){subtype_final="ETV6::RUNX1"}
  }
  
  if(is.na(subtype_final)){
    if(('ETV6::RUNX1' %in% gp_all & 'ETV6::RUNX1' %in% svm_all) & (pg_=='ETV6::RUNX1' | svm_=='ETV6::RUNX1')){
      subtype_final="ETV6::RUNX1-like"
    }
  }
  
  if(is.na(subtype_final)){
    if ("IKZF1 N159Y" %in% gp_all & "IKZF1 N159Y" %in% svm_all &
        (pg_=="IKZF1 N159Y" | svm_=="IKZF1 N159Y")){subtype_final="IKZF1 N159Y"}
  }
  
  if(is.na(subtype_final)){if(pg_=="KMT2A" & svm_=="KMT2A"){subtype_final="KMT2A-like"}}
  
  if(is.na(subtype_final)){if(pg_=="Low hypodiploid" & svm_=="Low hypodiploid"){subtype_final="Low hypodiploid"}}
  
  
  if(is.na(subtype_final)){if(pg_=="PAX5alt" & svm_=="PAX5alt"){subtype_final="PAX5alt"}}
  if(is.na(subtype_final)){if((pg_=="PAX5alt" | svm_=="PAX5alt") & grepl("PAX5",out_mutation$out_text_BALLmutation)){subtype_final="PAX5alt"}}
  
  if(is.na(subtype_final)){if(pg_=="Ph" & svm_=="Ph"){subtype_final="Ph-like"}}
  if(is.na(subtype_final)){if("Ph" %in% gp_all & "Ph" %in% svm_all & "Ph" %in% subtype_GEP){subtype_final="Ph-like"}}
  
  if(is.na(subtype_final)){if(pg_=="ZNF384" & svm_=="ZNF384"){subtype_final="ZNF384-like"}}
  
  if(is.na(subtype_final)){
    if(("CRLF2(non-Ph-like)" %in% fusion_fc_top$PossibleSubtype | "CRLF2(non-Ph-like)" %in% fusion_c_top$PossibleSubtype ) &
       "CRLF2" %in% subtype_exp &
       ((!"Ph" %in% pg_)|(!"Ph" %in% svm_))){subtype_final="CRLF2(non-Ph-like)"}
  }
  
  #Overwrite
  if(pg_=="Hyperdiploid" & "Hyperdiploid" %in% svm_all & "Low hyperdiploid" %in% subtype_cnv){subtype_final="Low hyperdiploid"}
  
  if(any(c('BCL2::IGH','IGH::BCL2',"IGH::MYC","MYC::IGH","IGH::CASC11","FGFR3::IGH","IGH::FGFR3") %in% c(fusion_c_top$FusionInFile,fusion_fc_top$FusionInFile)) &
     min(c(score_phenograph,score_svm))<0.8){
    subtype_final="BCL2/MYC"
    fusion_fc_=fusion_fc$FusionInFile[fusion_fc$PossibleSubtype=="BCL2/MYC"]
    fusion_c_=fusion_c$FusionInFile[fusion_c$PossibleSubtype=="BCL2/MYC"]}
  if(any(c("ETV6::RUNX1","RUNX1::ETV6") %in% c(fusion_c_top$FusionInFile,fusion_fc_top$FusionInFile))){subtype_final="ETV6::RUNX1"}
  
  if(("PAX5alt" %in% pg_ & "PAX5alt" %in% svm_) & grepl("PAX5",out_mutation$out_text_BALLmutation)){subtype_final="PAX5alt"}
  if(("PAX5alt" %in% pg_ & "PAX5alt" %in% svm_) & "iAMP21" %in% subtype_final){subtype_final="PAX5alt"}
  
  if((any(c("PAX5alt","Ph") %in% pg_) & any(c("PAX5alt","Ph") %in% svm_)) & "iAMP21" %in% subtype_final){subtype_final=paste0(gep_,collapse = "|");confidence="Medium"}
  
  if(("Ph" %in% pg_ & "Ph" %in% svm_) & "Ph-like" %in% subtype_fusion_GEP){subtype_final="Ph-like"}
  if(any(c("BCR::ABL1","ABL1::BCR") %in% c(fusion_fc_top$FusionInFile,fusion_c_top$FusionInFile))){subtype_final="Ph"}
  
  if("Near haploid" %in% subtype_cnv & any(c("Hyperdiploid","Low hypodiploid") %in% c(pg_,svm_))){subtype_final="Near haploid"}
  
  if("NUTM1" %in% subtype_fusion_GEP & "NUTM1" %in% subtype_exp){subtype_final="NUTM1"}
  if("TCF3::PBX1" %in% gp_all & "TCF3::PBX1" %in% svm_all & "TCF3::PBX1" %in% subtype_fusion_GEP){subtype_final="TCF3::PBX1"}
  if("ZNF384" %in% gp_all & "ZNF384" %in% svm_all & "ZNF384" %in% subtype_fusion_GEP){subtype_final="ZNF384"}
  
  if(is.na(subtype_final)){if(length(subtype_fusion_alone)==1 & "Ph-like" %in% subtype_fusion_alone){subtype_final="Ph-like"}}
  
  if(is.na(subtype_final)){subtype_final=paste0(gep_,collapse = "|");confidence="Medium"}
  
  subtype_final_=ifelse(pg_==svm_,subtype_final,"ManualCheckNeeded")
  
  # if("Low hyperdiploid" %in% pg_)
  
  #get output table ----
  df_sum=
    data.frame(
      sample_id=id,
      CDX2=df_feateure_exp$Expression[df_feateure_exp$Gene=="CDX2"],
      CRLF2=df_feateure_exp$Expression[df_feateure_exp$Gene=="CRLF2"],
      # PAX5=df_feateure_exp$Expression[df_feateure_exp$Gene=="PAX5"],
      # HLF=df_feateure_exp$Expression[df_feateure_exp$Gene=="HLF"],
      NUTM1=df_feateure_exp$Expression[df_feateure_exp$Gene=="NUTM1"],
      # MEGF10=df_feateure_exp$Expression[df_feateure_exp$Gene=="MEGF10"],
      # DUX4=df_feateure_exp$Expression[df_feateure_exp$Gene=="DUX4"],
      
      fusion_fc=paste0(fusion_fc_,collapse = ","),
      fusion_c=paste0(fusion_c_,collapse = ","),
      
      Mutation_BALL=gsub("\n","|",out_mutation$out_text_BALLmutation),
      Mutation_Sub_def=out_mutation$out_text_SubtypeDefiningMutation,
      
      RNAseqCNV_ChromN=chrom_n,
      RNAseqCNV_label=gsub("\n",";",CNV_label),
      Chr21Alteration=Chr21Alteration,
      
      subtype_phenograph=pg_,
      score_phenograph=score_phenograph,
      subtype_phenograph_label=subtype_phenograph_label,
      
      subtype_svm=svm_,
      score_svm=score_svm,
      subtype_svm_label=subtype_svm_label,
      
      subtype_exp=subtype_exp,
      subtype_mutation=out_mutation$subtype_mutation,
      subtype_cnv=subtype_cnv,
      
      subtype_fusion_GEP=paste0(subtype_fusion_GEP,collapse = ","),
      subtype_fusion_alone=paste0(subtype_fusion_alone,collapse = ","),
      
      subtype_GEP=paste0(gep_,collapse = "|"),
      
      subtype_final_possible=subtype_final,
      subtype_final=subtype_final_,
      confidence=ifelse(subtype_final_==subtype_final,confidence,NA),
      
      stringsAsFactors = F
    )
  df_sum
}

